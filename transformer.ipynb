{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (for Colab)\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 20:33:25.307423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from csv\n",
    "df = pd.read_csv('data/player_bios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (for Colab)\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tbryan2/nfl-prospects-nlp/main/data/player_bios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called player category that classifies players based on the NFL.com player grades\n",
    "df['Player Category'] = pd.cut(df['Player Grades'],\n",
    "                               bins=[0, 5.59, 5.69, 5.99, 6.09, 6.19,\n",
    "                                     6.29, 6.39, 6.49, 6.6, 6.9, 7.1, 7.5, 8],\n",
    "                               labels=['Priority Undrafted Free Agent',\n",
    "                                       'Candidate for Bottom of Roster or Practice Squad',\n",
    "                                       'Average Backup or Special Teamer',\n",
    "                                       'Traits or Talents to be Above-Average Backup',\n",
    "                                       'Good Backup with Potential to Develop into Starter',\n",
    "                                       'Will Eventually be Average Starter',\n",
    "                                       'Will Eventually be Plus Starter',\n",
    "                                       'Will become good starter within two years',\n",
    "                                       'Boom or Bust Potential',\n",
    "                                       'Year One Starter',\n",
    "                                       'Pro Bowl Talent',\n",
    "                                       'Perennial All-Pro',\n",
    "                                       'The Perfect Prospect'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Player Bio</th>\n",
       "      <th>Player Grades</th>\n",
       "      <th>Link</th>\n",
       "      <th>Player Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jadeveon Clowney</td>\n",
       "      <td>A physical specimen with a rare size-speed com...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>https://www.nfl.com/prospects/jadeveon-clowney...</td>\n",
       "      <td>Perennial All-Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sammy Watkins</td>\n",
       "      <td>A legitimate No. 1-caliber receiver who steppe...</td>\n",
       "      <td>7.10</td>\n",
       "      <td>https://www.nfl.com/prospects/sammy-watkins/32...</td>\n",
       "      <td>Pro Bowl Talent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anthony Barr</td>\n",
       "      <td>A highly disruptive, athletic specimen with th...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>https://www.nfl.com/prospects/anthony-barr/320...</td>\n",
       "      <td>Pro Bowl Talent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khalil Mack</td>\n",
       "      <td>A havoc-wreaking rush linebacker with the burs...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>https://www.nfl.com/prospects/khalil-mack/3200...</td>\n",
       "      <td>Pro Bowl Talent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jake Matthews</td>\n",
       "      <td>Smart, tough, versatile franchise left tackle ...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>https://www.nfl.com/prospects/jake-matthews/32...</td>\n",
       "      <td>Pro Bowl Talent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>Jeremy Webb</td>\n",
       "      <td>Webb is a Florida product but helped Stevenson...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>https://www.nfl.com/prospects/jeremy-webb/3200...</td>\n",
       "      <td>Priority Undrafted Free Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>Russ Yeast</td>\n",
       "      <td>Russ is the son of Craig Yeast, who was the SE...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>https://www.nfl.com/prospects/russ-yeast/32005...</td>\n",
       "      <td>Priority Undrafted Free Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>Ken Marks</td>\n",
       "      <td>Marks was known as \"Grandpa\" on the field as a...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>https://www.nfl.com/prospects/ken-marks/32004d...</td>\n",
       "      <td>Priority Undrafted Free Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>Devin Wynn</td>\n",
       "      <td>Wynn was coached by former Georgia and NFL run...</td>\n",
       "      <td>5.46</td>\n",
       "      <td>https://www.nfl.com/prospects/devin-wynn/32005...</td>\n",
       "      <td>Priority Undrafted Free Agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>Inoke Moala</td>\n",
       "      <td>Moala signed with Indiana State and then-head ...</td>\n",
       "      <td>5.40</td>\n",
       "      <td>https://www.nfl.com/prospects/inoke-moala/3200...</td>\n",
       "      <td>Priority Undrafted Free Agent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3969 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player                                         Player Bio  \\\n",
       "0     Jadeveon Clowney  A physical specimen with a rare size-speed com...   \n",
       "1        Sammy Watkins  A legitimate No. 1-caliber receiver who steppe...   \n",
       "2         Anthony Barr  A highly disruptive, athletic specimen with th...   \n",
       "3          Khalil Mack  A havoc-wreaking rush linebacker with the burs...   \n",
       "4        Jake Matthews  Smart, tough, versatile franchise left tackle ...   \n",
       "...                ...                                                ...   \n",
       "3964       Jeremy Webb  Webb is a Florida product but helped Stevenson...   \n",
       "3965        Russ Yeast  Russ is the son of Craig Yeast, who was the SE...   \n",
       "3966         Ken Marks  Marks was known as \"Grandpa\" on the field as a...   \n",
       "3967        Devin Wynn  Wynn was coached by former Georgia and NFL run...   \n",
       "3968       Inoke Moala  Moala signed with Indiana State and then-head ...   \n",
       "\n",
       "      Player Grades                                               Link  \\\n",
       "0              7.50  https://www.nfl.com/prospects/jadeveon-clowney...   \n",
       "1              7.10  https://www.nfl.com/prospects/sammy-watkins/32...   \n",
       "2              7.00  https://www.nfl.com/prospects/anthony-barr/320...   \n",
       "3              7.00  https://www.nfl.com/prospects/khalil-mack/3200...   \n",
       "4              7.00  https://www.nfl.com/prospects/jake-matthews/32...   \n",
       "...             ...                                                ...   \n",
       "3964           5.50  https://www.nfl.com/prospects/jeremy-webb/3200...   \n",
       "3965           5.50  https://www.nfl.com/prospects/russ-yeast/32005...   \n",
       "3966           5.49  https://www.nfl.com/prospects/ken-marks/32004d...   \n",
       "3967           5.46  https://www.nfl.com/prospects/devin-wynn/32005...   \n",
       "3968           5.40  https://www.nfl.com/prospects/inoke-moala/3200...   \n",
       "\n",
       "                    Player Category  \n",
       "0                 Perennial All-Pro  \n",
       "1                   Pro Bowl Talent  \n",
       "2                   Pro Bowl Talent  \n",
       "3                   Pro Bowl Talent  \n",
       "4                   Pro Bowl Talent  \n",
       "...                             ...  \n",
       "3964  Priority Undrafted Free Agent  \n",
       "3965  Priority Undrafted Free Agent  \n",
       "3966  Priority Undrafted Free Agent  \n",
       "3967  Priority Undrafted Free Agent  \n",
       "3968  Priority Undrafted Free Agent  \n",
       "\n",
       "[3969 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to use for fine-tuning the model with just the Player Bio and Player Category columns\n",
    "df_fine_tune = df[['Player Bio', 'Player Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.0/26.0 [00:00<00:00, 3.37kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.15k/1.15k [00:00<00:00, 430kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 5.45MB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 3.39MB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.36M/1.36M [00:00<00:00, 7.65MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Import a tokenizer from the transformers library\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train = df_fine_tune.sample(frac=0.8, random_state=0)\n",
    "test = df_fine_tune.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess the text\n",
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"Player Bio\"], truncation=True)\n",
    "\n",
    "\n",
    "# Preprocess the text in the train and test sets\n",
    "train_encodings = train.apply(preprocess_function, axis=1).reset_index()\n",
    "test_encodings = test.apply(preprocess_function, axis=1).reset_index()\n",
    "\n",
    "# Convert the train and test sets to arrays\n",
    "#train_encodings = train_encodings.to_numpy()\n",
    "#test_encodings = test_encodings.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up training, we will convert samples to tensors\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.63G/1.63G [00:34<00:00, 47.5MB/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import a base zero shot classification model to fine tune\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(\n",
    "       predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there are any values missing in the index column\n",
    "train_encodings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "repo_name = \"nfl-prospects\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encodings,\n",
    "    eval_dataset=test_encodings,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "838e51ec53c769d56e1cc4cb363682f0a508bbcae9a91bec1df886143b87e50b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
